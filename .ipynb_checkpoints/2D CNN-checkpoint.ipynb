{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Desktop\\desktop22\\MHEALTHDATASET\\ehealth_images\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['L1', 'L10', 'L11', 'L2', 'L3', 'L4', 'L5', 'L9']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "ORIGIN_PATH=os.getcwd()\n",
    "path = os.path.abspath(\"ehealth_images\")\n",
    "\n",
    "SIZE = 64\n",
    "dataset = []\n",
    "label = []\n",
    "DATA_class1=os.path.join(path,\"L1\")\n",
    "DATA_class2 = os.path.join(path,\"L2\")\n",
    "DATA_class3 = os.path.join(path,\"L3\")\n",
    "DATA_class4 = os.path.join(path,\"L4\")\n",
    "DATA_class5 = os.path.join(path,\"L5\")\n",
    "DATA_class6 = os.path.join(path,\"L9\")\n",
    "DATA_class7 = os.path.join(path,\"L10\")\n",
    "DATA_class8 = os.path.join(path,\"L11\")\n",
    "\n",
    "print(path)\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "\n",
    "L1_images = os.listdir(DATA_class1)\n",
    "\n",
    "for i, image_name in enumerate(L1_images):\n",
    "    try:\n",
    "\n",
    "        \n",
    "        image_path=os.path.join(DATA_class1,image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(1)\n",
    "    except Exception:\n",
    "        print(\"Could not read image {} with name {}\".format(i, image_name))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_images = os.listdir(DATA_class2)\n",
    "\n",
    "for i, image_name in enumerate(L2_images):\n",
    "    try:\n",
    "\n",
    "        \n",
    "        image_path=os.path.join(DATA_class2,image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(2)\n",
    "    except Exception:\n",
    "        print(\"Could not read image {} with name {}\".format(i, image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "L3_images = os.listdir(DATA_class3)\n",
    "\n",
    "for i, image_name in enumerate(L3_images):\n",
    "    try:\n",
    "\n",
    "        \n",
    "        image_path=os.path.join(DATA_class3,image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(3)\n",
    "    except Exception:\n",
    "        print(\"Could not read image {} with name {}\".format(i, image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "L4_images = os.listdir(DATA_class4)\n",
    "\n",
    "for i, image_name in enumerate(L4_images):\n",
    "    try:\n",
    "\n",
    "        \n",
    "        image_path=os.path.join(DATA_class4,image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(4)\n",
    "    except Exception:\n",
    "        print(\"Could not read image {} with name {}\".format(i, image_name))\n",
    "L5_images = os.listdir(DATA_class5)\n",
    "\n",
    "for i, image_name in enumerate(L5_images):\n",
    "    try:\n",
    "\n",
    "        \n",
    "        image_path=os.path.join(DATA_class5,image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(5)\n",
    "    except Exception:\n",
    "        print(\"Could not read image {} with name {}\".format(i, image_name))\n",
    "L6_images = os.listdir(DATA_class6)\n",
    "\n",
    "for i, image_name in enumerate(L6_images):\n",
    "    try:\n",
    "\n",
    "        \n",
    "        image_path=os.path.join(DATA_class6,image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(6)\n",
    "    except Exception:\n",
    "        print(\"Could not read image {} with name {}\".format(i, image_name))\n",
    "L7_images = os.listdir(DATA_class7)\n",
    "\n",
    "for i, image_name in enumerate(L7_images):\n",
    "    try:\n",
    "\n",
    "        \n",
    "        image_path=os.path.join(DATA_class7,image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(7)\n",
    "    except Exception:\n",
    "        print(\"Could not read image {} with name {}\".format(i, image_name))\n",
    "L8_images = os.listdir(DATA_class8)\n",
    "\n",
    "for i, image_name in enumerate(L8_images):\n",
    "    try:\n",
    "\n",
    "        \n",
    "        image_path=os.path.join(DATA_class8,image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = Image.fromarray(image, 'RGB')\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(0)\n",
    "    except Exception:\n",
    "        print(\"Could not read image {} with name {}\".format(i, image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960, 64, 64, 3)\n",
      "(768, 64, 64, 3)\n",
      "(768, 8)\n"
     ]
    }
   ],
   "source": [
    "image_data = np.array(dataset)\n",
    "print(image_data.shape)\n",
    "label = np.array(label)\n",
    "idx = np.arange(image_data.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "image_data = image_data[idx]\n",
    "label = label[idx]\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_data, to_categorical(np.array(label)), test_size = 0.20, random_state = 0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train/255.0\n",
    "# X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 31, 31, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6, 6, 16)          64        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               295424    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 326,904\n",
      "Trainable params: 325,656\n",
      "Non-trainable params: 1,248\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "height = 64\n",
    "width = 64\n",
    "classes = 8\n",
    "channels = 3\n",
    "chanDim = -1\n",
    "\n",
    "    \n",
    "inputShape = (height, width, channels)\n",
    "chanDim = -1\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu', input_shape = inputShape))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(BatchNormalization(axis = chanDim))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(BatchNormalization(axis = chanDim))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(16, (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(BatchNormalization(axis = chanDim))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "    \n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(BatchNormalization(axis = chanDim))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(classes, activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/35\n",
      "768/768 [==============================] - 13s 16ms/step - loss: 2.5602 - acc: 0.2799\n",
      "Epoch 2/35\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 1.7545 - acc: 0.4180\n",
      "Epoch 3/35\n",
      "768/768 [==============================] - 9s 11ms/step - loss: 1.4508 - acc: 0.5039\n",
      "Epoch 4/35\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 1.2329 - acc: 0.5443\n",
      "Epoch 5/35\n",
      "768/768 [==============================] - 7s 10ms/step - loss: 1.0395 - acc: 0.6120\n",
      "Epoch 6/35\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.9265 - acc: 0.6432\n",
      "Epoch 7/35\n",
      "768/768 [==============================] - 7s 10ms/step - loss: 0.8081 - acc: 0.6862\n",
      "Epoch 8/35\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 0.7795 - acc: 0.6979\n",
      "Epoch 9/35\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 0.7313 - acc: 0.7148\n",
      "Epoch 10/35\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 0.6453 - acc: 0.7617\n",
      "Epoch 11/35\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.6276 - acc: 0.7604\n",
      "Epoch 12/35\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 0.5275 - acc: 0.7865\n",
      "Epoch 13/35\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 0.5255 - acc: 0.8060\n",
      "Epoch 14/35\n",
      "768/768 [==============================] - 8s 11ms/step - loss: 0.5180 - acc: 0.7930\n",
      "Epoch 15/35\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.4837 - acc: 0.8138\n",
      "Epoch 16/35\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.4360 - acc: 0.8307\n",
      "Epoch 17/35\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.4690 - acc: 0.8138\n",
      "Epoch 18/35\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 0.3938 - acc: 0.8529\n",
      "Epoch 19/35\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 0.3575 - acc: 0.8685\n",
      "Epoch 20/35\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 0.3546 - acc: 0.8581\n",
      "Epoch 21/35\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 0.3562 - acc: 0.8672\n",
      "Epoch 22/35\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 0.3010 - acc: 0.8815\n",
      "Epoch 23/35\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.3371 - acc: 0.8672\n",
      "Epoch 24/35\n",
      "768/768 [==============================] - 9s 12ms/step - loss: 0.2951 - acc: 0.8932\n",
      "Epoch 25/35\n",
      "768/768 [==============================] - 8s 10ms/step - loss: 0.3039 - acc: 0.8893\n",
      "Epoch 26/35\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.2337 - acc: 0.9154\n",
      "Epoch 27/35\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.2684 - acc: 0.8958\n",
      "Epoch 28/35\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.2593 - acc: 0.8971\n",
      "Epoch 29/35\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.2913 - acc: 0.8789\n",
      "Epoch 30/35\n",
      "768/768 [==============================] - 7s 10ms/step - loss: 0.2269 - acc: 0.9167\n",
      "Epoch 31/35\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.2245 - acc: 0.9115\n",
      "Epoch 32/35\n",
      "768/768 [==============================] - 7s 10ms/step - loss: 0.2413 - acc: 0.9089\n",
      "Epoch 33/35\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.2043 - acc: 0.9219\n",
      "Epoch 34/35\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.2400 - acc: 0.9115\n",
      "Epoch 35/35\n",
      "768/768 [==============================] - 7s 9ms/step - loss: 0.2113 - acc: 0.9206\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(X_train, y_train, epochs = 35, batch_size = 32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.3420695861180623\n",
      "Test accuracy: 0.5520833333333334\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_5_input to have 3 dimensions, but got array with shape (768, 64, 64, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-e1471e2921bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m           \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m           validation_data=(X_test, y_test))\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected lstm_5_input to have 3 dimensions, but got array with shape (768, 64, 64, 3)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as KL\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Dropout, LSTM#, CuDNNLSTM\n",
    "model3 = Sequential()\n",
    "\n",
    "# IF you are running with a GPU, try out the CuDNNLSTM layer type instead (don't pass an activation, tanh is required)\n",
    "model3.add(LSTM(128, input_shape=(X_train.shape[2:]), activation='relu', return_sequences=True))\n",
    "model3.add(Dropout(0.2))\n",
    "\n",
    "model3.add(LSTM(128, activation='relu'))\n",
    "model3.add(Dropout(0.1))\n",
    "\n",
    "model3.add(Dense(32, activation='relu'))\n",
    "model3.add(Dropout(0.2))\n",
    "\n",
    "model3.add(Dense(8, activation='softmax'))\n",
    "\n",
    "# opt = SGD.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "# Compile model\n",
    "model3.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    "    optimizer='Adam'\n",
    ")\n",
    "\n",
    "model3.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=3,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
